# -*- coding: utf-8 -*-
"""rag.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pYeGtqDVnnXt_E0GpYSsMJzeEovw54DH
"""


# Commented out IPython magic to ensure Python compatibility.
# %pip install "unstructured[all-docs]" unstructured-client watermark langchain-groq langchain fastembed qdrant_client python-dotenv

import os

from langchain.chains import RetrievalQA
from langchain_community.document_loaders import TextLoader, UnstructuredPDFLoader, YoutubeLoader, PyPDFLoader
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain.indexes import VectorstoreIndexCreator
from langchain import  PromptTemplate
from langchain_groq import ChatGroq

from groq import Groq

# Set the environment variable
os.environ['GROQ_API_KEY'] = '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'

# Initialize the client using the environment variable
client = Groq(api_key=os.environ.get("GROQ_API_KEY"))

loader = PyPDFLoader("data.pdf")
pages = loader.load()

len(pages)
from langchain.text_splitter import CharacterTextSplitter
text_splitter = CharacterTextSplitter(
    separator="\n",
    chunk_size=1000,
    chunk_overlap=150,
    length_function=len
)

docs = text_splitter.split_documents(pages)

# Sử dụng mô hình embedding
MODEL_NAME = "sentence-transformers/all-MiniLM-L6-v2"
hf_embeddings = HuggingFaceEmbeddings(model_name=MODEL_NAME)

# Chuyển toàn bộ text thông qua mô hình embedding về dạng vector và lưu dưới dạng db
from langchain_community.vectorstores import FAISS

db = FAISS.from_documents(docs, hf_embeddings)

custom_prompt_template = """
You are a chatbot with extensive knowledge of Japanese history. Use the following information to answer the user's question.
If you don't know the answer, just say you don't know, don't try to make up an answer.

Context: {context}
Question: {question}

"""

prompt = PromptTemplate(template=custom_prompt_template,
                            input_variables=['context', 'question'])

from langchain.prompts.prompt import PromptTemplate
from langchain_groq import ChatGroq


retriever = db.as_retriever()

model =ChatGroq(
            groq_api_key=os.environ.get("GROQ_API_KEY"),
            model_name="gemma-7b-it" )


chain = RetrievalQA.from_chain_type(
    llm=model,
    chain_type="stuff",
    retriever=db.as_retriever(search_kwargs={"k": 2}),
    chain_type_kwargs={'prompt': prompt}
)

# response = chain.run("""Who is the de-facto leader of the Western Army in 1600 :
# ### Choices:
# A. Akechi Mitsuhide
# B. Mori Terumoto
# C. Tokugawa Ieyasu
# D. Ishida Mitsunari""")
# print(response)

def generate_response(question):
    response = chain({'query': question})
    return response['result']
